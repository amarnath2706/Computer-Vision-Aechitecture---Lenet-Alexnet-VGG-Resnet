{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 #Use the GPU memory 50%\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob #inside the folders how many sub folders are present?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "#train_path = 'Datasets/train'\n",
    "#valid_path = 'Datasets/test'\n",
    "\n",
    "train_path='C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\train'\n",
    "valid_path='C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "#Preprocessing  - reuse with some modifications\n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "#Here i am going to take the weights, what ever weights they had stored during training iam going to retreive those weights \n",
    "#If we failed to provide the weights('Imagenet') then it starts the training from Scratch.\n",
    "#include_top = False -->  Default 1000 outputs but in our case only 2 outputs, It skips the flatten and output layer and we can add our own flatten layer and output layer\n",
    "#include_top=True(which means - whole architecture - input,flatten,output from the VGG16 for Imagenet classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "# Dont train the weights from scratch or dont update the weight and my weights are fixed.\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\train\\\\diseased cotton leaf',\n",
       " 'C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\train\\\\diseased cotton plant',\n",
       " 'C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\train\\\\fresh cotton leaf',\n",
       " 'C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\train\\\\fresh cotton plant']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # useful for getting number of output classes\n",
    "#folders = glob('Datasets/train/*')\n",
    "folders = glob('C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\train\\*')\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Layer\n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg16.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output Layer\n",
    "prediction = Dense(len(folders), activation='softmax')(x) # x - appending my flatten layer(x) with dense layer\n",
    "\n",
    "# create a model object  by combining the entire input's and output's to create the dense neural network\n",
    "#Here vgg16 is the model or variable that we have created early\n",
    "model = Model(inputs=vgg16.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 100356    \n",
      "=================================================================\n",
      "Total params: 14,815,044\n",
      "Trainable params: 100,356\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view the structure of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass classification(softmax) - so we have used categorical_crossentropy as a loss function\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1951 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 27s 450ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0769 - val_accuracy: 0.9623\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=1,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_vgg16_CottonDisease.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model=load_model('model_vgg16_CottonDisease.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\test\\\\diseased cotton plant\\\\dd (895)_iaip.jpg', target_size = (224, 224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "#covert the array values in to noramalize values\n",
    "test_image=test_image/255\n",
    "#Exapnd the dimensions\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0887417e-05, 9.9369872e-01, 1.5739720e-06, 6.2787849e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diseased cotton plant\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:\\\\Users\\\\Asus-2020\\\\Downloads\\\\Cotton Disease\\\\test\\\\diseased cotton plant\\\\dd (895)_iaip.jpg', target_size = (224, 224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "#a=np.argmax(model.predict(test_image), axis=1)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'diseased cotton leaf'\n",
    "    print(prediction)\n",
    "elif result[0][1]==1:\n",
    "    prediction=\"diseased cotton plant\"\n",
    "    print(prediction)\n",
    "elif result[0][2]==1:\n",
    "    prediction=\"fresh cotton leaf\"\n",
    "    print(prediction)\n",
    "\n",
    "else:\n",
    "    prediction = 'fresh cotton plant'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
