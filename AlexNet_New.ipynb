{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
    " Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Get Data\n",
    "#import tflearn.datasets.oxflower17 as oxflower17\n",
    "#x, y = oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 3003      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 28,082,755\n",
      "Trainable params: 28,061,619\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (3) Create a sequential model\n",
    "model = Sequential()\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),\\\n",
    " strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# (4) Compile \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\\\n",
    " metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 images belonging to 3 classes.\n",
      "Found 37 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.3518 - accuracy: 0.3784 - val_loss: 0.8442 - val_accuracy: 0.4324\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 2.1214 - accuracy: 0.5135 - val_loss: 4.6772 - val_accuracy: 0.3784\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.7936 - accuracy: 0.3784 - val_loss: 3.8995 - val_accuracy: 0.3784\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 2.1749 - accuracy: 0.3784 - val_loss: 23.7559 - val_accuracy: 0.3784\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.7544 - accuracy: 0.5135 - val_loss: 37.9511 - val_accuracy: 0.3784\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.2460 - accuracy: 0.6216 - val_loss: 124.9443 - val_accuracy: 0.3784\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.0906 - accuracy: 0.5946 - val_loss: 217.2070 - val_accuracy: 0.3784\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.7472 - accuracy: 0.5405 - val_loss: 194.0462 - val_accuracy: 0.3784\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.5260 - accuracy: 0.5676 - val_loss: 126.8791 - val_accuracy: 0.3784\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 14s 5s/step - loss: 1.0274 - accuracy: 0.6757 - val_loss: 51.3284 - val_accuracy: 0.2973\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.2844 - accuracy: 0.5946 - val_loss: 28.0706 - val_accuracy: 0.3784\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.3221 - accuracy: 0.5676 - val_loss: 69.7304 - val_accuracy: 0.3784\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.8827 - accuracy: 0.5676 - val_loss: 71.0709 - val_accuracy: 0.3784\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.2934 - accuracy: 0.4865 - val_loss: 18.2055 - val_accuracy: 0.3784\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.1317 - accuracy: 0.6216 - val_loss: 77.0789 - val_accuracy: 0.3784\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 14s 5s/step - loss: 1.0966 - accuracy: 0.6216 - val_loss: 59.4665 - val_accuracy: 0.4054\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.3018 - accuracy: 0.4865 - val_loss: 51.4998 - val_accuracy: 0.4054\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.0390 - accuracy: 0.6757 - val_loss: 29.0932 - val_accuracy: 0.4054\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.1651 - accuracy: 0.5676 - val_loss: 13.1411 - val_accuracy: 0.4324\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.9184 - accuracy: 0.7568 - val_loss: 21.8773 - val_accuracy: 0.4595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x68742420f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('F:/Dataset/Alexnet/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('F:/Dataset/Alexnet/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = len(training_set),\n",
    "                         epochs = 20,\n",
    "                         validation_data = test_set,    \n",
    "                         validation_steps = len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]]\n",
      "Sachin\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('F:/Dataset/Alexnet/S13.jpg', target_size = (224, 224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Apj'\n",
    "    print(prediction)\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 'Dhoni'\n",
    "    print(prediction)\n",
    "    \n",
    "else:\n",
    "    prediction = 'Sachin'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
